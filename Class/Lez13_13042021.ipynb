{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lez13 13042021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIYL/JLeXPth1KS4X8V8ot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedeleDelvecchio/MLPNS/blob/main/Class/Lez13_13042021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mzjku1b_WQd"
      },
      "source": [
        "Facciamo un account kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggcpc-1R_WEZ"
      },
      "source": [
        "#Feature engineering.\n",
        "\n",
        "There is a phase of data science which is feature extraction or feature engineering: portion of the analysis that we did when we fitted a line to out data to porduce a lower dimenisonal representation of the data.\n",
        "\n",
        "The idea id that we can work with the raw representation of our data, in the sense that are the native feature that I am using. Without standardizing I cannot compare shape, I am only comparing absolute numbers. \n",
        "\n",
        "Wikipedia says: Feature engineering is the process of using domain knowledge to \t  extract features from raw data. These features can be used to improve the performance of \t  machine learning algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw1NoVvyLUZ3"
      },
      "source": [
        "**If I wanna study trend I absolutely have to standardize.** In the midterm we used each datapoint as feature, so I am using 60 feature, and I dont like working in high dim feature space. \n",
        "\n",
        "Using raw representation has some porblem:\n",
        "\n",
        "1. scalability: if I am using 60 feature and I have 258 time series is a very complex computational problem, calculating distances...\n",
        "\n",
        "2. time series may be asynchronous: I can have same behaviour but in different place, so this migh not be caputure using raw native feature, but might be capture using polinomial fit. I may capture that curvature is the same, but happening in different place\n",
        "\n",
        "**The alternative is choose low dimenisonality representation of the data, which can be anthing. For example take the mean and std. dev. , choosing that based on the specific problem. I can extract statistical quantity, or parametric feature (fit something to data and extract parameter from that) to reduce dimensionality.**\n",
        "Another technique is the Principle Component Anlaysis (PCA).  \n",
        "\n",
        "Make sure my lower representation of data preserves the pairwise similarities between the data. The fit does that because if the shape of the time series si similar than the convexity of polinomial I am fitting is similar. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgggOgSIN_7X"
      },
      "source": [
        "#**SUPERVISE LEARNING**\n",
        "\n",
        "Now we study the **supervised learning: is what I do if I want to CLASSIFY or PREDICT.**\n",
        "\n",
        "**In supervise learning you are trying to understand similariry between objects by example. I have data set that is completely observed, so I observed all input and output varibale and I wanna unerstand parents that relate input and output variable, so that I can extend it for object for which I have not observed output variable.**\n",
        "\n",
        "My target variable (output variable) can be a class (categorical variable, for an image) for example, or it can be a value (temperature of earth). All depends on having a labels, and I have labels for object htat are of the same nature of object I want to predict.\n",
        "\n",
        "##SVM\n",
        "\n",
        "**If I have bunch of datapoint: for some of them I have observed 3 feature (x, y and color) and another subsets of datapoint I observe only (x and y). I wanna see if there anythings between x and y that can lead me to decide if the color is more likely ot be blu or yellow, based on the other color observation.**\n",
        "\n",
        "One method that we are **not** going to explore is the SVM (support vector machine). But let's describe it: I create a plane into an hyperspace. An hyperplane is n-1 dimensional (where n is the dimenison of space). This methods finds the optimal line based on the distance from each one of the point in space. \n",
        "\n",
        "I create a curve to separate my space.\n",
        "\n",
        "\n",
        "#TREE METHODS\n",
        "\n",
        "https://slides.com/federicabianco/mlpns5\n",
        "\n",
        "**We do somethings similar to SVM (dividing space and see wether a point fall inside or outside this line that divides the plane), but I am not allow to move diagonally in feature space. I move only parallel to cooridnate with straight line. For every feature I can only establish a acondition that has 2 outcomes: \"true or false\" for categorical or \"bigger or smaller\" for numerical varibale. In this way I create a vertical line to separet blu or yellow in x axis, and create another line along y (horizontal line).** \n",
        "\n",
        "We are gonna talk a lot about tree methods. It split spaces along each axis separately It seems a downgraded version of SVM: **but there can be cases in wich three methods are better.\n",
        "The example is if one of my axes is a categorical variable, I cannot create a curve (matematical formula) based on a categorical variable. Say fro example if in one of my axeis I have animal species, unless I do one hot encoding and doing other algorithm. THis because I cannot do math with categorical variable. \n",
        "\n",
        "This method allows me to have a hybrid feature space. And since varibale are trated separately I cannot have covariance, and this is a good things!**\n",
        "\n",
        "#Nearest Neighbors\n",
        "\n",
        "KNearest Neighbors: it is a flexible method.\n",
        "\n",
        "\n",
        "I measure distance, so it is defined for numerical varibale, since I can't define distance in categorical spaces like we said, but it's hard to have distance. \n",
        "\n",
        "**So I calculate the distance between target point and all point in space. I select the four closest point and predict that the target varibale that I want to predict is the most common variable I found in my Nearest Neighbors. \"K\" stands for how many neighbour I consider.**\n",
        "\n",
        "I am gonna appling the prediction based on what is the value for the NN. It's kind of like the rule for supervised learning, but with more complex decision process. \n",
        "\n",
        "This methods work very well (gives small error) if the KNN surroud our object. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfloONrRd962"
      },
      "source": [
        "#lazy learner\n",
        "\n",
        "1. calculate the distance d to all known objects\n",
        "(this scales with number of object in training set, so I have to calculate m_object*n_disance*d, where d is the dimesnion fo the distance, i.e. dimenison of feature space --> I have a large computational loss) \n",
        "2. select the k closest objects.\n",
        "\n",
        "3. assign the most common among the k classes\n",
        "\n",
        "BUT I don't have to do this iteratively, just to assing label to object!\n",
        "This is a non parametric model. I am defining only the distance but I have to choose only one parameter that is K. This pproduce a stable results. \n",
        "\n",
        "I can quantify the error for this model KNN for K that tends to infinity. \n",
        "\n",
        "One things that is not good about KNN is that the similarity in feature space reflect hte similarity in label then it is predicted.\n",
        "This method is poor if training is sparse. And it is poor if there are outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGtcVioDgsqz"
      },
      "source": [
        "#**Setting up with kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VgERvLxXE8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828768d1-76ce-469f-d15b-60b33b079920"
      },
      "source": [
        "import pylab as pl\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "%pylab inline\n",
        "\n",
        "pl.style.use(\"bmh\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7r_Lp5pvjDt"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzY82zJFvvsw",
        "outputId": "36eda809-a6d7-4f4b-c236-59466b144889"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZDlLs6twuOV",
        "outputId": "a8acaaa7-98d8-4ef3-918a-89b27b23dbda"
      },
      "source": [
        "cd drive/MyDrive/MLPNS/"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/MLPNS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0XHkqIBwVRk",
        "outputId": "a7222cba-4ba8-4311-925c-bc656db8d5b5"
      },
      "source": [
        "ls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bootcampNB.ipynb\n",
            " busBusses.npy\n",
            " busTimeTable.npy\n",
            " CEDIT_6_5_Friuli_Italy_1976.cpg\n",
            " CEDIT_6_5_Friuli_Italy_1976.dbf\n",
            " CEDIT_6_5_Friuli_Italy_1976.prj\n",
            " CEDIT_6_5_Friuli_Italy_1976.sbn\n",
            " CEDIT_6_5_Friuli_Italy_1976.sbx\n",
            " CEDIT_6_5_Friuli_Italy_1976.shp\n",
            " CEDIT_6_5_Friuli_Italy_1976.shp.xml\n",
            " CEDIT_6_5_Friuli_Italy_1976.shx\n",
            "'CEDIT_6_5_Friuli_Italy_1976.zip?raw=true'\n",
            " country_pop.xls\n",
            " demo1.py\n",
            " demo2.py\n",
            " demo3.py\n",
            " e68ceb0a193e4e378b29255b62ab75e0_0.geojson\n",
            " flatiron_building_new_york_city-111.jpg\n",
            " grb050525A.csv\n",
            " healthcare-dataset-stroke-data.csv\n",
            " inclassNB2016.ipynb\n",
            " inclassNB2017.ipynb\n",
            " inclassNB2018.ipynb\n",
            " ispalindrome.cpython-37.pyc\n",
            " ispalindrome.py\n",
            " \u001b[0m\u001b[01;34mkaggleHiggs\u001b[0m/\n",
            " kaggle.json\n",
            " kalbar_drone_190113-768x512.jpg\n",
            " LoopExercise.ipynb\n",
            " LoopExerciseSolution.ipynb\n",
            " Mona_Lisa.png\n",
            " NYCskyline.jpg\n",
            " NYC_Women_s_Resource_Network_Database.csv\n",
            " PandasDataWrangling-Chap7.ipynb\n",
            " playwPandas.ipynb\n",
            " printGoodmorningGoodAfternoon_instructions.py\n",
            " printGoodmorningGoodAfternoon.py\n",
            " pyboot2020_2.ipynb\n",
            " pyboot2020.ipynb\n",
            " pyBootParma.ipynb\n",
            " readingData.ipynb\n",
            " README.md\n",
            " spm-20210427T111354Z-001.zip\n",
            " stroke-prediction-dataset.zip\n",
            "'view?usp=sharing'\n",
            " ZIP_CODE_040114.dbf\n",
            " ZIP_CODE_040114.prj\n",
            " ZIP_CODE_040114.sbn\n",
            " ZIP_CODE_040114.sbx\n",
            " ZIP_CODE_040114.shp\n",
            " ZIP_CODE_040114.shp.xml\n",
            " ZIP_CODE_040114.shx\n",
            " ZIP_CODE_040114.zip\n",
            "'ZIP_CODE_040114.zip?raw=true'\n",
            "'ZIP_CODE_040114.zip?raw=true.1'\n",
            "'ZIP_CODE_040114.zip?raw=true.2'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VzXH5eGXGt-",
        "outputId": "dd9c733e-c73e-4e25-c046-d2b3d337e15f"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQLi2x3xiFeu"
      },
      "source": [
        "kaggle.json contain my credential about kaggle, stored as the same syntax as pyton dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61HR0e2-XQ2Z",
        "outputId": "12266086-5d26-400c-f87d-6ec68d831fa7"
      },
      "source": [
        " !ls kaggle.json"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sn-7SqXn69l"
      },
      "source": [
        "now change permission mode on file, so that notebook can acces to .json file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytwCJwjJXUQB"
      },
      "source": [
        "!chmod 600 kaggle.json"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtJ8iPp3ZRgb"
      },
      "source": [
        "envs = json.load(open(\"kaggle.json\", \"r\"))\n",
        "os.environ[\"KAGGLE_USERNAME\"] = envs['username']\n",
        "os.environ[\"KAGGLE_KEY\"] = envs['key'] "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry4XLG9Xohyj"
      },
      "source": [
        "Now I have access to kaggle. So let's see what are the file tht contain the word \"stroke\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaBAEJLnZZ74",
        "outputId": "ef24b5b3-e02a-4e22-e398-8294ed7bbda1"
      },
      "source": [
        "!kaggle datasets list -s stroke"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                            title                                            size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------------------  ----------------------------------------------  -----  -------------------  -------------  \n",
            "fedesoriano/stroke-prediction-dataset                          Stroke Prediction Dataset                        67KB  2021-01-26 19:29:28          27313  \n",
            "mazharkarimi/heart-disease-and-stroke-prevention               Heart Disease and Stroke Prevention               1MB  2018-05-14 10:36:48           7755  \n",
            "google/tinyquickdraw                                           QuickDraw Sketches                               11GB  2018-04-18 19:38:04           3025  \n",
            "valkling/tappy-keystroke-data-with-parkinsons-patients         Tappy Keystroke Data with Parkinson's Patients   96MB  2018-02-04 05:41:47           1032  \n",
            "lirilkumaramal/heart-stroke                                    Heart Stroke                                    560KB  2020-10-26 11:39:50            256  \n",
            "mpwolke/cusersmarildownloadsstrokecsv                          Stroke  Deaths 30 days hospital admission.      633KB  2020-05-03 19:09:31            165  \n",
            "derekdb/toronto-robot-stroke-posture-dataset                   Toronto Rehab Stroke Pose Dataset               113MB  2018-08-27 20:59:52            718  \n",
            "rishidamarla/heart-disease-prediction                          Heart Disease Prediction                          3KB  2020-08-23 01:18:14           1096  \n",
            "robseidl/tennis-atp-tour-australian-open-final-2019            Tennis ATP Tour Australian Open Final 2019       27KB  2019-03-02 20:52:43           1806  \n",
            "carnegiecylab/keystroke-dynamics-benchmark-data-set            Keystroke Dynamics - Benchmark Data Set           1MB  2019-12-03 16:04:59             89  \n",
            "alanchn31/stroke-mortality                                     Stroke Mortality                                  2MB  2020-10-03 03:27:30            117  \n",
            "dileep070/heart-disease-prediction-using-logistic-regression     Logistic regression To predict heart disease   58KB  2019-06-07 06:12:56          11717  \n",
            "ruddfawcett/hanzidb                                            HanziDB                                         246KB  2017-10-03 16:03:59            339  \n",
            "kaitavmehta/facial-droop-and-facial-paralysis-image            Facial_Droop_and_Facial_Paralysis_image          19MB  2019-08-23 17:24:06            104  \n",
            "fedesoriano/hepatitis-c-dataset                                Hepatitis C Prediction Dataset                   15KB  2020-12-21 16:50:55            463  \n",
            "michelheusser/handwritten-digits-and-operators                 Dataset: Handwritten Digits and Operators       205MB  2020-07-13 17:23:23            145  \n",
            "corrphilip/numeral-gestures                                    Numeral Gestures recorded on iOS                 34MB  2017-08-24 16:22:16            358  \n",
            "higgstachyon/kannada-mnist                                     Kannada_MNIST                                    56MB  2019-08-04 00:52:15            793  \n",
            "christofel04/cardiovascular-study-dataset-predict-heart-disea  Cardiovascular Study Dataset                     75KB  2020-09-22 12:24:18            958  \n",
            "fazilbtopal/auto85                                             1985 Automobile Dataset                          11KB  2019-03-18 13:22:11           1825  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEqnA75NaHu5",
        "outputId": "2c0343ad-fcdc-468d-eab1-a2651d393007"
      },
      "source": [
        "!kaggle datasets download fedesoriano/stroke-prediction-dataset"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stroke-prediction-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osFhyeecaVma",
        "outputId": "bd566dbe-3a58-46a0-f2be-1291e48500fe"
      },
      "source": [
        "!unzip stroke-prediction-dataset.zip"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  stroke-prediction-dataset.zip\n",
            "replace healthcare-dataset-stroke-data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: healthcare-dataset-stroke-data.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scft1_F8phcO",
        "outputId": "1913760f-bc45-4763-fd73-a7536413ce22"
      },
      "source": [
        "ls"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bootcampNB.ipynb\n",
            " busBusses.npy\n",
            " busTimeTable.npy\n",
            " CEDIT_6_5_Friuli_Italy_1976.cpg\n",
            " CEDIT_6_5_Friuli_Italy_1976.dbf\n",
            " CEDIT_6_5_Friuli_Italy_1976.prj\n",
            " CEDIT_6_5_Friuli_Italy_1976.sbn\n",
            " CEDIT_6_5_Friuli_Italy_1976.sbx\n",
            " CEDIT_6_5_Friuli_Italy_1976.shp\n",
            " CEDIT_6_5_Friuli_Italy_1976.shp.xml\n",
            " CEDIT_6_5_Friuli_Italy_1976.shx\n",
            "'CEDIT_6_5_Friuli_Italy_1976.zip?raw=true'\n",
            " country_pop.xls\n",
            " demo1.py\n",
            " demo2.py\n",
            " demo3.py\n",
            " e68ceb0a193e4e378b29255b62ab75e0_0.geojson\n",
            " flatiron_building_new_york_city-111.jpg\n",
            " grb050525A.csv\n",
            " healthcare-dataset-stroke-data.csv\n",
            " inclassNB2016.ipynb\n",
            " inclassNB2017.ipynb\n",
            " inclassNB2018.ipynb\n",
            " ispalindrome.cpython-37.pyc\n",
            " ispalindrome.py\n",
            " \u001b[0m\u001b[01;34mkaggleHiggs\u001b[0m/\n",
            " kaggle.json\n",
            " kalbar_drone_190113-768x512.jpg\n",
            " LoopExercise.ipynb\n",
            " LoopExerciseSolution.ipynb\n",
            " Mona_Lisa.png\n",
            " NYCskyline.jpg\n",
            " NYC_Women_s_Resource_Network_Database.csv\n",
            " PandasDataWrangling-Chap7.ipynb\n",
            " playwPandas.ipynb\n",
            " printGoodmorningGoodAfternoon_instructions.py\n",
            " printGoodmorningGoodAfternoon.py\n",
            " pyboot2020_2.ipynb\n",
            " pyboot2020.ipynb\n",
            " pyBootParma.ipynb\n",
            " readingData.ipynb\n",
            " README.md\n",
            " spm-20210427T111354Z-001.zip\n",
            " stroke-prediction-dataset.zip\n",
            "'view?usp=sharing'\n",
            " ZIP_CODE_040114.dbf\n",
            " ZIP_CODE_040114.prj\n",
            " ZIP_CODE_040114.sbn\n",
            " ZIP_CODE_040114.sbx\n",
            " ZIP_CODE_040114.shp\n",
            " ZIP_CODE_040114.shp.xml\n",
            " ZIP_CODE_040114.shx\n",
            " ZIP_CODE_040114.zip\n",
            "'ZIP_CODE_040114.zip?raw=true'\n",
            "'ZIP_CODE_040114.zip?raw=true.1'\n",
            "'ZIP_CODE_040114.zip?raw=true.2'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Eq2fOc0anC_"
      },
      "source": [
        "datain = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "zTlt5ua1asox",
        "outputId": "9107f136-b49c-445d-af99-ea312df047ce"
      },
      "source": [
        "datain "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51676</td>\n",
              "      <td>Female</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>202.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>18234</td>\n",
              "      <td>Female</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>83.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>44873</td>\n",
              "      <td>Female</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Urban</td>\n",
              "      <td>125.20</td>\n",
              "      <td>40.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>19723</td>\n",
              "      <td>Female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>82.99</td>\n",
              "      <td>30.6</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>37544</td>\n",
              "      <td>Male</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>166.29</td>\n",
              "      <td>25.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>44679</td>\n",
              "      <td>Female</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Govt_job</td>\n",
              "      <td>Urban</td>\n",
              "      <td>85.28</td>\n",
              "      <td>26.2</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5110 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  gender   age  ...   bmi   smoking_status stroke\n",
              "0      9046    Male  67.0  ...  36.6  formerly smoked      1\n",
              "1     51676  Female  61.0  ...   NaN     never smoked      1\n",
              "2     31112    Male  80.0  ...  32.5     never smoked      1\n",
              "3     60182  Female  49.0  ...  34.4           smokes      1\n",
              "4      1665  Female  79.0  ...  24.0     never smoked      1\n",
              "...     ...     ...   ...  ...   ...              ...    ...\n",
              "5105  18234  Female  80.0  ...   NaN     never smoked      0\n",
              "5106  44873  Female  81.0  ...  40.0     never smoked      0\n",
              "5107  19723  Female  35.0  ...  30.6     never smoked      0\n",
              "5108  37544    Male  51.0  ...  25.6  formerly smoked      0\n",
              "5109  44679  Female  44.0  ...  26.2          Unknown      0\n",
              "\n",
              "[5110 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4D0S7s1prKT"
      },
      "source": [
        "See the statistical properties of the data. I wanna predict wether a person will have a stroke based on nuemrical value as \"age\", \"hypertenison\", \"avg_glucose_level\", \"bmi\". We will find an very accurate prediciton, but the prediction will be meaningless, as we will see."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "A0rKPQzrathT",
        "outputId": "e2982564-a0e2-4926-94e9-a6e40a537687"
      },
      "source": [
        "datain.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "      <td>4909.000000</td>\n",
              "      <td>5110.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>36517.829354</td>\n",
              "      <td>43.226614</td>\n",
              "      <td>0.097456</td>\n",
              "      <td>0.054012</td>\n",
              "      <td>106.147677</td>\n",
              "      <td>28.893237</td>\n",
              "      <td>0.048728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>21161.721625</td>\n",
              "      <td>22.612647</td>\n",
              "      <td>0.296607</td>\n",
              "      <td>0.226063</td>\n",
              "      <td>45.283560</td>\n",
              "      <td>7.854067</td>\n",
              "      <td>0.215320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>67.000000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>55.120000</td>\n",
              "      <td>10.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>17741.250000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>77.245000</td>\n",
              "      <td>23.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>36932.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.885000</td>\n",
              "      <td>28.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>54682.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>114.090000</td>\n",
              "      <td>33.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>72940.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>271.740000</td>\n",
              "      <td>97.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id          age  ...          bmi       stroke\n",
              "count   5110.000000  5110.000000  ...  4909.000000  5110.000000\n",
              "mean   36517.829354    43.226614  ...    28.893237     0.048728\n",
              "std    21161.721625    22.612647  ...     7.854067     0.215320\n",
              "min       67.000000     0.080000  ...    10.300000     0.000000\n",
              "25%    17741.250000    25.000000  ...    23.500000     0.000000\n",
              "50%    36932.000000    45.000000  ...    28.100000     0.000000\n",
              "75%    54682.000000    61.000000  ...    33.100000     0.000000\n",
              "max    72940.000000    82.000000  ...    97.600000     1.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0tTpJYqa2NF",
        "outputId": "55bae214-72c1-4cd2-f7fa-c304c95fad54"
      },
      "source": [
        "datain.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                     int64\n",
              "gender                object\n",
              "age                  float64\n",
              "hypertension           int64\n",
              "heart_disease          int64\n",
              "ever_married          object\n",
              "work_type             object\n",
              "Residence_type        object\n",
              "avg_glucose_level    float64\n",
              "bmi                  float64\n",
              "smoking_status        object\n",
              "stroke                 int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "CGpHDyHva46O",
        "outputId": "4c45477e-eabe-4595-a02c-8154be1873b7"
      },
      "source": [
        "strokeInput = datain[\"age\", \"hypertenison\", \"avg_glucose_level\", \"bmi\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ('age', 'hypertenison', 'avg_glucose_level', 'bmi')",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-a79477f54200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstrokeInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hypertenison\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg_glucose_level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bmi\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ('age', 'hypertenison', 'avg_glucose_level', 'bmi')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usmX3TMtbH8U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}